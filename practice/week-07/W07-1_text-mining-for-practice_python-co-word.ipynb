{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT MINING for PRACTICE: 동시출현 매트릭스\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!wget -O data/article_sample.txt https://raw.githubusercontent.com/thejungwon/text-mining-course/master/practice/week-07/data/article_sample.txt\n",
    "!wget -O data/stopword.txt https://raw.githubusercontent.com/thejungwon/text-mining-course/master/practice/week-07/data/stopword.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 전처리 후 Term 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "contents = []\n",
    "with open('data/article_sample.txt', encoding=\"utf-8\") as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        #0: 토픽, 1: 출처, 2: 날짜, 3: 제목, 4: 내용 \n",
    "        contents.append(row[4])      \n",
    "\n",
    "stops_words = []\n",
    "with open('data/stopword.txt', encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        stops_words.append(line.strip())\n",
    "stops_words+=[\n",
    "    '것', '수', '등'\n",
    "]\n",
    "POS_LIST = [\"Noun\"]\n",
    "tokenized_sentence_list = []\n",
    "for content in contents:\n",
    "    tokens = []\n",
    "    for pos in okt.pos(content):\n",
    "        #Q Condition 부분을 완성하시오\n",
    "        condition = pos[1] in POS_LIST and pos[0] not in stops_words\n",
    "        if condition:\n",
    "            tokens.append(pos[0])\n",
    "    tokenized_sentence_list.append(tokens)\n",
    "\n",
    "tokenized_sentence_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 동시출현 빈도 저장 key = (word1, word2), value = 횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}   #동시출현 빈도가 저장될 dict\n",
    "for article in tokenized_sentence_list:\n",
    "    article = list(set(article))\n",
    "    for i, a in enumerate(article):\n",
    "        for b in article[i:]:\n",
    "            @TODO\n",
    "            if True: continue   #같은 단어의 경우는 세지 않음\n",
    "            @TODO    \n",
    "            if True: continue   #A, B와 B, A가 다르게 세어지는것을 막기 위해 항상 a < b로 순서 고정\n",
    "            @TODO\n",
    "            count[a, b] = 1   #실제로 센다\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 빈도 순으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@TODO\n",
    "sorted_x = count\n",
    "sorted_x[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top N 빈번한 조합 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#행/열의 이름을 나타내기 위한 과정\n",
    "unique_terms = []\n",
    "for k,v in sorted_x[:TOP_N]:\n",
    "    unique_terms+=list(k)\n",
    "print(len(unique_terms))\n",
    "\n",
    "@TODO\n",
    "unique_terms=unique_terms\n",
    "\n",
    "print(len(unique_terms))\n",
    "unique_terms= sorted(unique_terms)\n",
    "unique_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 매트릭스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word_index = {}\n",
    "for index, term in enumerate(unique_terms):\n",
    "    word_index[term] = index\n",
    "print(word_index)\n",
    "\n",
    "matrix = np.zeros((len(unique_terms),len(unique_terms)))\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 해당하는 위치에 빈도 값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "for k,v in sorted_x[:TOP_N]:\n",
    "    matrix[word_index[k[0]],word_index[k[1]]] = v\n",
    "    matrix[word_index[k[1]],word_index[k[0]]] = v\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "\n",
    "#한쪽만 완성하고 복사할 수 있지 않을까?\n",
    "for k,v in sorted_x[:30]:\n",
    "    matrix[word_index[k[0]],word_index[k[1]]] = v\n",
    "@TODO\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Heat Map으로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n",
    "\n",
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (N, M).\n",
    "    row_labels\n",
    "        A list or array of length N with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length M with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=[\"black\", \"white\"],\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A list or array of two color specifications.  The first is used for\n",
    "        values below a threshold, the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic'\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "im, cbar = heatmap(matrix, unique_terms, unique_terms, ax=ax,\n",
    "                   cmap=\"YlGn\", )\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:.1f} t\")\n",
    "\n",
    "# fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 그래프로 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "nxg = nx.complete_graph(10)\n",
    "G = Network(notebook=\"True\")\n",
    "G.from_nx(nxg)\n",
    "G.show(\"example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "got_net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\", notebook=True)\n",
    "\n",
    "# set the physics layout of the network\n",
    "got_net.barnes_hut()\n",
    "\n",
    "for e,v in sorted_x[:100]:\n",
    "    src = e[0]\n",
    "    dst = e[1]\n",
    "    w = v\n",
    "\n",
    "    got_net.add_node(src, src, title=src)\n",
    "    got_net.add_node(dst, dst, title=dst)\n",
    "    got_net.add_edge(src, dst, value=w)\n",
    "\n",
    "neighbor_map = got_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in got_net.nodes:\n",
    "    node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "    node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "got_net.show(\"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
