{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT MINING for PRACTICE: 그 외 텍스트 데이터 수집 방법\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Speech to Text (STT)\n",
    "- 음성을 텍스트로 바꾸는 머신러닝 모델로, 자막 생성등에 자주 쓰임 (유튜브).\n",
    "- 또한 모든 음성 인식 어플리케이션들도 결국에는 텍스트 데이터를 기반으로 명령을 인식 받기 때문에, 우리가 흔히 말하는 AI에는 필수적인 단계\n",
    "- 직접 학습을 시킬 수도 있지만, 아무리 최선을 다해서 학습시켜도 큰 기업의 API의 성능을 뛰어넘기란 쉽지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 구글 API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키 파일을 이렇게 전달\n",
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"google_key.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트를 추출할 음성 파일\n",
    "import IPython.display as ipd\n",
    "ipd.Audio('resources/tajja_mono.wav') # load a local WAV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.google.com/speech-to-text/docs/quickstart-client-libraries\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "\n",
    "# Instantiates a client\n",
    "client = speech.SpeechClient()\n",
    "\n",
    "# The name of the audio file to transcribe\n",
    "file_name = os.path.join(\n",
    "    'resources',\n",
    "    'tajja_mono.wav')\n",
    "\n",
    "# Loads the audio into memory\n",
    "with io.open(file_name, 'rb') as audio_file:\n",
    "    content = audio_file.read()\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=16000,\n",
    "    language_code='ko-KR')\n",
    "\n",
    "# Detects speech in the audio file\n",
    "response = client.recognize(config, audio)\n",
    "\n",
    "for result in response.results:\n",
    "    print('Transcript: {}'.format(result.alternatives[0].transcript))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. NAVER Clova API활용\n",
    "- 한국어의 경우에는 국내 API가 성능이 더 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = \"YOUR_CLIENT_ID\"\n",
    "CLIENT_SECRET = \"CLIENT_SECRET\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://apidocs.ncloud.com/ko/ai-naver/clova_speech_recognition/stt/\n",
    "import sys\n",
    "import requests\n",
    "client_id = CLIENT_ID\n",
    "client_secret = CLIENT_SECRET\n",
    "lang = \"Kor\" # 언어 코드 ( Kor, Jpn, Eng, Chn )\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=\" + lang\n",
    "file_name = os.path.join(\n",
    "    'resources',\n",
    "    'tajja_mono.wav')\n",
    "data = open(file_name, 'rb')\n",
    "headers = {\n",
    "    \"X-NCP-APIGW-API-KEY-ID\": client_id,\n",
    "    \"X-NCP-APIGW-API-KEY\": client_secret,\n",
    "    \"Content-Type\": \"application/octet-stream\"\n",
    "}\n",
    "response = requests.post(url,  data=data, headers=headers)\n",
    "rescode = response.status_code\n",
    "if(rescode == 200):\n",
    "    print (response.text)\n",
    "else:\n",
    "    print(\"Error : \" + response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optical character recognition (OCR)\n",
    "- OCR같은 경우는 Image recognition의 일종으로, 사람 (human)의 인식 능력과 큰 차이가 나지 않음\n",
    "- 하지만 컴퓨터의 속도와 무한히 일을 시킬 수 있다는 점에서, 사람의 능력을 뛰어 넘었다고 볼 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Google Vision API 활용\n",
    "- Image recognition task의 경우에는 상대적으로 음성에 비해 어느 정도 성능이 수렴되어 있기 때문에, 어떤 API를 써도 크게 상관없음\n",
    "- 단, 손 글씨의 경우에는 차이가 있을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.google.com/vision/docs/ocr#vision_text_detection-python\n",
    "\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/mopobridge.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detect_text(\"resources/mopobridge.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text to Speech (TTS)\n",
    "- Machine Learning 적용 이전 부터 존재했던 기술로, 위의 두 가지에 비해 상대적으로 어렵지 않음\n",
    "- 단, 진짜 사람처럼 말하는 TTS를 만드는 것은 Machine Learning 기술에 의존 해야함 (예:GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "client_id = CLIENT_ID\n",
    "client_secret = CLIENT_SECRET\n",
    "encText = urllib.parse.quote(\"이렇게 텍스트 마이닝을 사랑해주셔서 정말 감사드립니다.\")\n",
    "data = \"speaker=mijin&speed=0&text=\" + encText;\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/voice/v1/tts\"\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-NCP-APIGW-API-KEY-ID\",client_id)\n",
    "request.add_header(\"X-NCP-APIGW-API-KEY\",client_secret)\n",
    "response = urllib.request.urlopen(request, data=data.encode('utf-8'))\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    response_body = response.read()\n",
    "    with open('resources/result.mp3', 'wb') as f:\n",
    "        f.write(response_body)\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#음성파일 확인\n",
    "import IPython.display as ipd\n",
    "ipd.Audio('resources/result.mp3') # load a local WAV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK. 한국어의 위대함을 극복해보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/korean.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. 이미지를 텍스트로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "detect_text(\"resources/korean.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 크게 달라지지 않았습니다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/translate01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. 텍스트를 음성으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "client_id = CLIENT_ID\n",
    "client_secret = CLIENT_SECRET\n",
    "encText = urllib.parse.quote(\"\"\"한꾹인똘만알아뽈쑤있께 짝썽하겠씁니다.\n",
    "히까씨이케부쿠로역에썬\n",
    "30초또안껄릴만끔가깝찌만쑥쏘까많이 낙후되어있꼬\n",
    "엘베없꼬4층이라짐많으면깨꼬쌩합니따.\n",
    "빠뀌뻘레나왔꼬 화짱씰 많이낡았씁니따.\n",
    "끄래써 똥 역화짱씰까써 쌌씁니따\n",
    "쩔때 여끼로오찌마쎄요!\n",
    "뜨럽꼬 낡꼬 꼐딴을 좋아하씨는 뿐만 까쎄요!\"\"\")\n",
    "data = \"speaker=mijin&speed=0&text=\" + encText;\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/voice/v1/tts\"\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header(\"X-NCP-APIGW-API-KEY-ID\",client_id)\n",
    "request.add_header(\"X-NCP-APIGW-API-KEY\",client_secret)\n",
    "response = urllib.request.urlopen(request, data=data.encode('utf-8'))\n",
    "rescode = response.getcode()\n",
    "if(rescode==200):\n",
    "    print(\"TTS mp3 저장\")\n",
    "    response_body = response.read()\n",
    "    with open('resources/result_korean.mp3', 'wb') as f:\n",
    "        f.write(response_body)\n",
    "else:\n",
    "    print(\"Error Code:\" + rescode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#음성파일 확인\n",
    "ipd.Audio('resources/result_korean.mp3') # load a local WAV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 음성을 또 텍스트로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://apidocs.ncloud.com/ko/ai-naver/clova_speech_recognition/stt/\n",
    "import sys\n",
    "import requests\n",
    "client_id = CLIENT_ID\n",
    "client_secret = CLIENT_SECRET\n",
    "lang = \"Kor\" # 언어 코드 ( Kor, Jpn, Eng, Chn )\n",
    "url = \"https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=\" + lang\n",
    "file_name = os.path.join(\n",
    "    'resources',\n",
    "    'result_korean.mp3')\n",
    "data = open(file_name, 'rb')\n",
    "headers = {\n",
    "    \"X-NCP-APIGW-API-KEY-ID\": client_id,\n",
    "    \"X-NCP-APIGW-API-KEY\": client_secret,\n",
    "    \"Content-Type\": \"application/octet-stream\"\n",
    "}\n",
    "response = requests.post(url,  data=data, headers=headers)\n",
    "rescode = response.status_code\n",
    "if(rescode == 200):\n",
    "    print (response.text)\n",
    "else:\n",
    "    print(\"Error : \" + response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "완벽하지는 않지만, 이제 해석이 가능합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/translate02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 다른 창의적인 방법 또 생각해보기!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/korean2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](resources/korean3.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
